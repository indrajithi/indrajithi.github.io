<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Machine Learning Approach to Classify Music Based on Genre | Indrajith Indraprastham</title><meta name=keywords content><meta name=description content="Music Genre Classifier Demo Music is categorized into subjective categories called genres. With the growth of the internet and multimedia, systems applications that deal with the musical databases gained importance and demand for Music Information Retrieval (MIR) applications increased.
Musical genres have no strict definitions and boundaries as they arise through a complex interaction between the public, marketing, historical, and cultural factors. We are going to create an application that accepts a music file and classify it in to genres."><meta name=author content="Indrajith Indraprastham"><link rel=canonical href=https://indrajith.me/posts/machine-learning-pproach-to-classify-music-based-on-genre/><link crossorigin=anonymous href=/assets/css/stylesheet.min.0a1e554ccf592c7aea3491499fc50f6b1eebbd432b10152f2f456629bc538b9e.css integrity="sha256-Ch5VTM9ZLHrqNJFJn8UPax7rvUMrEBUvL0VmKbxTi54=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://indrajith.me/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://indrajith.me/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://indrajith.me/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://indrajith.me/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://indrajith.me/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="Machine Learning Approach to Classify Music Based on Genre"><meta property="og:description" content="Music Genre Classifier Demo Music is categorized into subjective categories called genres. With the growth of the internet and multimedia, systems applications that deal with the musical databases gained importance and demand for Music Information Retrieval (MIR) applications increased.
Musical genres have no strict definitions and boundaries as they arise through a complex interaction between the public, marketing, historical, and cultural factors. We are going to create an application that accepts a music file and classify it in to genres."><meta property="og:type" content="article"><meta property="og:url" content="https://indrajith.me/posts/machine-learning-pproach-to-classify-music-based-on-genre/"><meta property="og:image" content="https://indrajith.me/dp.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2017-07-29T11:58:29+05:30"><meta property="article:modified_time" content="2017-07-29T11:58:29+05:30"><meta property="og:site_name" content="Indrajith Indraprastham"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://indrajith.me/dp.jpg"><meta name=twitter:title content="Machine Learning Approach to Classify Music Based on Genre"><meta name=twitter:description content="Music Genre Classifier Demo Music is categorized into subjective categories called genres. With the growth of the internet and multimedia, systems applications that deal with the musical databases gained importance and demand for Music Information Retrieval (MIR) applications increased.
Musical genres have no strict definitions and boundaries as they arise through a complex interaction between the public, marketing, historical, and cultural factors. We are going to create an application that accepts a music file and classify it in to genres."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://indrajith.me/posts/"},{"@type":"ListItem","position":2,"name":"Machine Learning Approach to Classify Music Based on Genre","item":"https://indrajith.me/posts/machine-learning-pproach-to-classify-music-based-on-genre/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Machine Learning Approach to Classify Music Based on Genre","name":"Machine Learning Approach to Classify Music Based on Genre","description":"Music Genre Classifier Demo Music is categorized into subjective categories called genres. With the growth of the internet and multimedia, systems applications that deal with the musical databases gained importance and demand for Music Information Retrieval (MIR) applications increased.\nMusical genres have no strict definitions and boundaries as they arise through a complex interaction between the public, marketing, historical, and cultural factors. We are going to create an application that accepts a music file and classify it in to genres.","keywords":[],"articleBody":"Music Genre Classifier Demo Music is categorized into subjective categories called genres. With the growth of the internet and multimedia, systems applications that deal with the musical databases gained importance and demand for Music Information Retrieval (MIR) applications increased.\nMusical genres have no strict definitions and boundaries as they arise through a complex interaction between the public, marketing, historical, and cultural factors. We are going to create an application that accepts a music file and classify it in to genres.\nRequirements  Django (1.11) Numpy (1.12.1) Scikit-Learn (0.18.1) Scipy (0.19.0) Python-Speech-Features (0.5) Pydub (0.18.0)  Installation  git clone https://github.com/indrajithi/mgc-django.git pip install -r requirements.txt python manage.py migrate python manage.py runserver App will run on localhost:8000  Music Genre Classifier Our app is written in Python using Django framework. We are using a trained Poly Kernel SVM for finding the genre.\nOur web application uses the package mysvm which we developed to extract features and to find the genre.\nWe have developed a python package called mysvm for extracting features and classifying music. This package is added to our App. On receiving a request for genre label, we convert the file to .wav if it is in other format. Then the features are extracted from the audio file using mysvm.feature.extract (filename).\nPrototype We need to find the best classification algorithm that can be used in our App. Matlab is ideal to implement machine learning algorithms in minimum lines of code. Before making the App in python we made a prototype in Matlab.\nFeature Extraction We chose to extract MFCC from the audio files as the feature. For finding MFCC in Matlab, we have used HTK MFCC MATLAB toolkit. The output will be a matrix of 13n dimensional vector. Where n depends on the total duration of the audio. 13(100*sec).\nWhile feature extraction we were getting ‘nan’(not a number) and infinity in the output. This is usually caused be a division by zero or a very small number closed to 0 resulting in infinity/nan in the output. This could be a regular result or some algorithm or implementation error in the MFCC toolkit. To overcome this situation, we have set nan or infinity entries in the feature array to 0.\nPrincipal Component Analysis. Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components (or sometimes, principal modes of variation) [7]. After doing a PCA on the data we got 90% variance and should reduce the feature dimension.\n[input2, eigvec, eigvalue] = pca (ds. input); cumvar = cumsum(eigvalue); //cumulative sum n(n+1)/2 cumvarpercent = cumvar/cumvar(end)*100; Dimensionality reduction Various researchers take statistics such as mean variance IQR, etc., to reduce the feature dimension. Some researchers model it using multivariate regression and some fit it to a Gaussian mixture model. Here we are taking the mean and upper diagonal variance of 13*n MFCC coefficients. The result is a feature vector of size 104.\n%Reducing Feature Dimeansion mf = mean(mm,2); %row mean cf = cov(mm'); % covariance ff = mf; for i=0:(size(mm,1)-1) ff = [ff;diag(cf,i)]; %use diagonals  end t(:,end+1) = ff(:,1); Classification K-nearest neighbors (KNN) Principle is that the data instance of the same class should be closer in the feature space. For a given data point x of unknown class, we can compute the distance between x and all the data points in the training data and assign the class determined by k nearest points of x.\nSuppose we are given training dataset of n points. {(x1,y1),(x2,y2)…(xn,yn)} Where (xi,yi) represents data pair i. xi- feature vector yi- target class For a new data point x the most likely class is determined by finding the distance from all training data points (Euclidian distance). The output class will be the class which k nearest neighbors belongs to. K is a predefined integer (k=1, k=2, k=3.)\nLogistic Regression Logistic Regression is one of the widely used classification algorithm. This algorithm is used in medical as well as business fields for analytics and classification. This model has the hypothesis function 0 ≤h (x) ≤ 1. Where hθ(x) = 11 + e-θTx called as Sigmoid or Logistic Function. For binary class classification y ∈{0, 1}. The output of this classifier will be a probability of the given input belonging to class 1. Ifhθ(x)outputs 0.7 it means that the given input has 70% chance of belonging to class 1. Since we have 10 genre classes y ∈{0, 1 .. 9}we used one-vs-all method for classification.\nPython package mysvm We developed a python package called mysvm which contains three modules: features, svm, acc. These are used by the web application in feature extraction and finding genre. This package also contains many other functions to do complicated feature extraction and classification.\n├── acc.py ├── data │ ├── classifier_10class.pkl │ ├── classifier_10class_prob.pkl │ ├── cmpr.pkl │ └── Xall.npy ├── feature.py ├── __init__.py ├── svm.py feature This module is used to extract MFCC features from a given file. It contains the following functions.\n extract (file): Extract features from a given file. Files in other formats are converted to .wav format. Returns numpy array. extract_all (audio_dir): Extracts features from all files in a directory. extract_ratio (train_ratio, test_ratio, audio_dir) : Extract features from all files in a directory in a ratio. Returns two numpy arrays. geny(n): Generates Y values for n classes. Returns numpy array. gen_suby(sub, n): Generates Y values for a subset of classes. Returns numpy array. gen_labels( ): Returns a list of all genre labels. flattern( x) : Flatterns a numpy array.  svm A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. This module contains various functions for classification using support vector machines.\n  poly(X,Y): Trains a poly kernel SVM by fitting X, Y dataset. Returns a trained poly kernel SVM classifier.\n  fit ( training_percentage, fold): Randomly choose songs from the dataset, and train the classifier. Accepts parameter: train_percentage, fold; Returns trained classifier.\n  getprob (filename): Find the probabilities for a song belongs to each genre. Returns a dictionary mapping genre names to probability and a list of top 3 genres which is having probability of more than 0.15.\n  random_cross_validation (train_percentage,fold): Randomly cross validate with training percentage and fold. Accepts parameter: train_percentage, fold;\n  findsubclass (class_count): Returns all possible ways we can combine the classes. Accepts an integer as class count. Returns numpy array of all possible combination.\n  gen_sub_data (class_l): Generate a subset of the dataset for the given list of classes. Returns numpy array.\n  fitsvm (Xall, Yall, class_l, train_percentage, fold): Fits a poly kernel svm and returns the accuracy. Accepts parameter: train_percentage; fold; Returns: classifier, Accuracy.\n  best_combinations (class_l, train_percentage, fold): Finds all possible combination of classes and the accuracy for the given number of classes Accepts: Training percentage, and number of folds Returns: A List of best combination possible for given the class count.\n  getgenre (filename): Accepts a filename and returns a genre label for a given file.\n  getgenreMulti (filename): Accepts a filename and returns top three genre labels based on the probability.\n  acc Module for finding the accuracy.\n get ( res, test ) :\nCompares two arrays and returns the accuracy of their match.  Results    Classifier Training Accuracy Testing Accuracy     K-Nearest Neighbors  53%   Logistic Regression 75.778% 54%   SVM Linear Kernel 99% 52%   SVM RBF Kernel 99% 12%   SVM Poly Kernel 99% 64%    6 genre classes we are getting an accuracy of 85%\nConclusion We have tried various machine learning algorithms for this project. Our aim is to get maximum accuracy. We have found from our research that we can a get maximum accuracy of 65% by using poly kernel SVM for 10 genre classes. We have also tried to find the best combination of genre classes which will result in maximum accuracy. If we choose 6 genre classes we were able to get an accuracy of 85%. We chose these labels for the Web Application [classical, hip-hop, jazz, metal, pop and rock] For some songs we can say that it has feature of multiple genres. So we have also tried to get multiple label outputs based on the probability.\n","wordCount":"1368","inLanguage":"en","datePublished":"2017-07-29T11:58:29+05:30","dateModified":"2017-07-29T11:58:29+05:30","author":{"@type":"Person","name":"Indrajith Indraprastham"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://indrajith.me/posts/machine-learning-pproach-to-classify-music-based-on-genre/"},"publisher":{"@type":"Organization","name":"Indrajith Indraprastham","logo":{"@type":"ImageObject","url":"https://indrajith.me/%3Clink%20/%20abs%20url%3E"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove('dark')</script><header class=header><nav class=nav><div class=logo><a href=https://indrajith.me/ accesskey=h title="< /> (Alt + H)">&lt; /></a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://indrajith.me/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://indrajith.me/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://indrajith.me/credits/ title=Credits><span>Credits</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://indrajith.me/>Home</a>&nbsp;»&nbsp;<a href=https://indrajith.me/posts/>Posts</a></div><h1 class=post-title>Machine Learning Approach to Classify Music Based on Genre</h1><div class=post-meta><span title="2017-07-29 11:58:29 +0530 IST">July 29, 2017</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Indrajith Indraprastham</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#music-genre-classifier aria-label="Music Genre Classifier">Music Genre Classifier</a><ul><ul><li><a href=#demohttpsgenreclassifierherokuappcom aria-label=Demo><a href=https://genreclassifier.herokuapp.com/>Demo</a></a></li></ul><li><a href=#requirements aria-label=Requirements>Requirements</a></li><li><a href=#installation aria-label=Installation>Installation</a></li><li><a href=#music-genre-classifier-1 aria-label="Music Genre Classifier">Music Genre Classifier</a></li><li><a href=#prototypehttpsgithubcomindrajithimusic-genre-classification-matlab aria-label=Prototype><a href=https://github.com/indrajithi/music-genre-classification-matlab>Prototype</a></a><ul><li><a href=#feature-extraction aria-label="Feature Extraction">Feature Extraction</a></li><li><a href=#principal-component-analysis aria-label="Principal Component Analysis.">Principal Component Analysis.</a></li><li><a href=#dimensionality-reduction aria-label="Dimensionality reduction">Dimensionality reduction</a></li><li><a href=#classification aria-label=Classification>Classification</a><ul><li><a href=#k-nearest-neighbors-knn aria-label="K-nearest neighbors (KNN)">K-nearest neighbors (KNN)</a></li><li><a href=#logistic-regression aria-label="Logistic Regression">Logistic Regression</a></li></ul></li></ul></li><li><a href=#python-package-mysvm aria-label="Python package mysvm">Python package <em>mysvm</em></a><ul><li><a href=#feature aria-label=feature><em>feature</em></a></li><li><a href=#svm aria-label=svm><em>svm</em></a></li><li><a href=#acc aria-label=acc><em>acc</em></a></li></ul></li></ul></li><li><a href=#results aria-label=Results>Results</a><ul><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li></ul></li></ul></div></details></div><div class=post-content><h1 id=music-genre-classifier>Music Genre Classifier<a hidden class=anchor aria-hidden=true href=#music-genre-classifier>#</a></h1><p><img loading=lazy src=/mgc.jpg alt=Screenshot></p><h3 id=demohttpsgenreclassifierherokuappcom><a href=https://genreclassifier.herokuapp.com/>Demo</a><a hidden class=anchor aria-hidden=true href=#demohttpsgenreclassifierherokuappcom>#</a></h3><p>Music is categorized into subjective categories called genres. With the growth of the internet and multimedia, systems applications that deal with the musical databases gained importance and demand for Music Information Retrieval (MIR) applications increased.</p><p>Musical genres have no strict definitions and boundaries as they arise through a complex interaction between the public, marketing, historical, and cultural factors. We are going to create an application that accepts a music file and classify it in to genres.</p><h2 id=requirements>Requirements<a hidden class=anchor aria-hidden=true href=#requirements>#</a></h2><ul><li>Django (1.11)</li><li>Numpy (1.12.1)</li><li>Scikit-Learn (0.18.1)</li><li>Scipy (0.19.0)</li><li>Python-Speech-Features (0.5)</li><li>Pydub (0.18.0)</li></ul><h2 id=installation>Installation<a hidden class=anchor aria-hidden=true href=#installation>#</a></h2><ul><li><code>git clone https://github.com/indrajithi/mgc-django.git</code></li><li><code>pip install -r requirements.txt</code></li><li><code>python manage.py migrate</code></li><li><code>python manage.py runserver</code></li><li><em>App will run on</em> <code>localhost:8000</code></li></ul><h2 id=music-genre-classifier-1>Music Genre Classifier<a hidden class=anchor aria-hidden=true href=#music-genre-classifier-1>#</a></h2><p>Our app is written in Python using Django framework. We are using a trained <code>Poly Kernel SVM</code> for finding the genre.</p><p>Our web application uses the package <code>mysvm</code> which we developed to extract features and to find the genre.</p><p>We have developed a python package called <a href=https://github.com/indrajithi/mgc-python>mysvm</a> for extracting features and classifying music. This package is added to our App. On receiving a request for genre label, we convert the file to <code>.wav</code> if it is in other format. Then the features are extracted from the audio file using <code>mysvm.feature.extract (filename)</code>.</p><h2 id=prototypehttpsgithubcomindrajithimusic-genre-classification-matlab><a href=https://github.com/indrajithi/music-genre-classification-matlab>Prototype</a><a hidden class=anchor aria-hidden=true href=#prototypehttpsgithubcomindrajithimusic-genre-classification-matlab>#</a></h2><p>We need to find the best classification algorithm that can be used in our App. Matlab is ideal to implement machine learning algorithms in minimum lines of code. Before making the App in python we made a prototype in Matlab.</p><h3 id=feature-extraction>Feature Extraction<a hidden class=anchor aria-hidden=true href=#feature-extraction>#</a></h3><p>We chose to extract MFCC from the audio files as the feature. For finding MFCC in Matlab, we have used HTK MFCC MATLAB toolkit. The output will be a matrix of 13<em>n dimensional vector. Where n depends on the total duration of the audio. 13</em>(100*sec).<br>While feature extraction we were getting ‘nan’(not a number) and infinity in the output. This is usually caused be a division by zero or a very small number closed to 0 resulting in infinity/nan in the output. This could be a regular result or some algorithm or implementation error in the MFCC toolkit. To overcome this situation, we have set nan or infinity entries in the feature array to 0.</p><h3 id=principal-component-analysis>Principal Component Analysis.<a hidden class=anchor aria-hidden=true href=#principal-component-analysis>#</a></h3><p>Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components (or sometimes, principal modes of variation) [7]. After doing a PCA on the data we got 90% variance and should reduce the feature dimension.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-matlab data-lang=matlab>[input2, eigvec, eigvalue] = pca (ds. input);
cumvar = cumsum(eigvalue); <span style=color:#f92672>//</span>cumulative sum n(n<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>)<span style=color:#f92672>/</span><span style=color:#ae81ff>2</span>
cumvarpercent = cumvar<span style=color:#f92672>/</span>cumvar(<span style=color:#66d9ef>end</span>)<span style=color:#f92672>*</span><span style=color:#ae81ff>100</span>;
</code></pre></div><h3 id=dimensionality-reduction>Dimensionality reduction<a hidden class=anchor aria-hidden=true href=#dimensionality-reduction>#</a></h3><p>Various researchers take statistics such as mean variance IQR, etc., to reduce the feature dimension. Some researchers model it using multivariate regression and some fit it to a Gaussian mixture model. Here we are taking the mean and upper diagonal variance of 13*n MFCC coefficients. The result is a feature vector of size 104.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-matlab data-lang=matlab><span style=color:#75715e>%Reducing Feature Dimeansion</span>
mf = mean(mm,<span style=color:#ae81ff>2</span>); <span style=color:#75715e>%row mean</span>
cf = cov(mm<span style=color:#f92672>&#39;</span>); <span style=color:#75715e>% covariance</span>
ff = mf;
   <span style=color:#66d9ef>for</span> i=<span style=color:#ae81ff>0</span>:(size(mm,<span style=color:#ae81ff>1</span>)<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
    ff = [ff;diag(cf,i)]; <span style=color:#75715e>%use diagonals </span>
   <span style=color:#66d9ef>end</span>
t(:,<span style=color:#66d9ef>end</span><span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>) = ff(:,<span style=color:#ae81ff>1</span>);
</code></pre></div><h3 id=classification>Classification<a hidden class=anchor aria-hidden=true href=#classification>#</a></h3><h4 id=k-nearest-neighbors-knn>K-nearest neighbors (KNN)<a hidden class=anchor aria-hidden=true href=#k-nearest-neighbors-knn>#</a></h4><p>Principle is that the data instance of the same class should be closer in the feature space.
For a given data point x of unknown class, we can compute the distance between x and all
the data points in the training data and assign the class determined by k nearest points of x.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-matlab data-lang=matlab>Suppose we are given training dataset of n points.
{(x1,y1),(x2,y2)…(xn,yn)}
    Where (xi,yi) represents data pair i.
xi<span style=color:#f92672>-</span> feature vector
yi<span style=color:#f92672>-</span> target class
</code></pre></div><p>For a new data point x the most likely class is determined by finding the distance from all training data points (Euclidian distance). The output class will be the class which k nearest neighbors belongs to. K is a predefined integer (k=1, k=2, k=3.)</p><h4 id=logistic-regression>Logistic Regression<a hidden class=anchor aria-hidden=true href=#logistic-regression>#</a></h4><p>Logistic Regression is one of the widely used classification algorithm. This algorithm is used in medical as well as business fields for analytics and classification. This model has the hypothesis function <code>0 ≤h (x) ≤ 1.</code> Where <code>hθ(x) = 11 + e-θTx </code>called as Sigmoid or Logistic Function. For binary class classification<code> y ∈{0, 1}</code>. The output of this classifier will be a probability of the given input belonging to class 1. If<code>hθ(x)</code>outputs 0.7 it means that the given input has 70% chance of belonging to class 1. Since we have 10 genre classes <code>y ∈{0, 1 .. 9}</code>we used one-vs-all method for classification.</p><h2 id=python-package-mysvm>Python package <em>mysvm</em><a hidden class=anchor aria-hidden=true href=#python-package-mysvm>#</a></h2><p>We developed a python package called <code>mysvm</code> which contains three modules: <em>features, svm, acc</em>. These are used by the web application in feature extraction and finding genre. This package also contains many other functions to do complicated feature extraction and classification.</p><pre><code>├── acc.py
├── data
│   ├── classifier_10class.pkl
│   ├── classifier_10class_prob.pkl
│   ├── cmpr.pkl
│   └── Xall.npy
├── feature.py
├── __init__.py
├── svm.py
</code></pre><h3 id=feature><em>feature</em><a hidden class=anchor aria-hidden=true href=#feature>#</a></h3><p>This module is used to extract MFCC features from a given file. It contains the following functions.</p><ul><li><em><strong>extract (file):</strong></em>
Extract features from a given file. Files in other formats are converted to .wav format. Returns numpy array.</li><li><em><strong>extract_all (audio_dir):</strong></em>
Extracts features from all files in a directory.</li><li><em><strong>extract_ratio (train_ratio, test_ratio, audio_dir) :</strong></em>
Extract features from all files in a directory in a ratio. Returns two numpy arrays.</li><li><em><strong>geny(n):</strong></em>
Generates <code>Y</code> values for <code>n</code> classes. Returns numpy array.</li><li><em><strong>gen_suby(sub, n):</strong></em>
Generates <code>Y</code> values for a subset of classes. Returns numpy array.</li><li><em><strong>gen_labels( ):</strong></em>
Returns a list of all genre labels.</li><li><em><strong>flattern( x) :</strong></em>
Flatterns a numpy array.</li></ul><h3 id=svm><em>svm</em><a hidden class=anchor aria-hidden=true href=#svm>#</a></h3><p>A Support Vector Machine (SVM) is a discriminative classifier formally defined by a separating hyperplane. In other words, given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. This module contains various functions for classification using support vector machines.</p><ul><li><p><em><strong>poly(X,Y):</strong></em>
Trains a poly kernel SVM by fitting X, Y dataset. Returns a trained poly kernel SVM classifier.</p></li><li><p><em><strong>fit ( training_percentage, fold):</strong></em>
Randomly choose songs from the dataset, and train the classifier. Accepts parameter: <code>train_percentage, fold</code>; Returns trained classifier.</p></li><li><p><em><strong>getprob (filename):</strong></em>
Find the probabilities for a song belongs to each genre. Returns a dictionary mapping genre names to probability and a list of top 3 genres which is having probability of more than 0.15.</p></li><li><p><em><strong>random_cross_validation (train_percentage,fold):</strong></em>
Randomly cross validate with training percentage and fold. Accepts parameter: <code>train_percentage, fold</code>;</p></li><li><p><em><strong>findsubclass (class_count):</strong></em>
Returns all possible ways we can combine the classes. Accepts an integer as class count. Returns numpy array of all possible combination.</p></li><li><p><em><strong>gen_sub_data (class_l):</strong></em>
Generate a subset of the dataset for the given list of classes. Returns numpy array.</p></li><li><p><em><strong>fitsvm (Xall, Yall, class_l, train_percentage, fold):</strong></em>
Fits a poly kernel svm and returns the accuracy. Accepts parameter: <code>train_percentage; fold</code>; Returns: classifier, Accuracy.</p></li><li><p><em><strong>best_combinations (class_l, train_percentage, fold):</strong></em>
Finds all possible combination of classes and the accuracy for the given number of classes Accepts: Training percentage, and number of folds Returns: A List of best combination possible for given the class count.</p></li><li><p><em><strong>getgenre (filename):</strong></em>
Accepts a filename and returns a genre label for a given file.</p></li><li><p><em><strong>getgenreMulti (filename):</strong></em>
Accepts a filename and returns top three genre labels based on the probability.</p></li></ul><h3 id=acc><em>acc</em><a hidden class=anchor aria-hidden=true href=#acc>#</a></h3><p>Module for finding the accuracy.</p><ul><li><strong>get ( res, test ) :</strong><br>Compares two arrays and returns the accuracy of their match.</li></ul><h1 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h1><table><thead><tr><th style=text-align:center>Classifier</th><th style=text-align:center>Training Accuracy</th><th style=text-align:center>Testing Accuracy</th></tr></thead><tbody><tr><td style=text-align:center>K-Nearest Neighbors</td><td style=text-align:center></td><td style=text-align:center>53%</td></tr><tr><td style=text-align:center>Logistic Regression</td><td style=text-align:center>75.778%</td><td style=text-align:center>54%</td></tr><tr><td style=text-align:center>SVM Linear Kernel</td><td style=text-align:center>99%</td><td style=text-align:center>52%</td></tr><tr><td style=text-align:center>SVM RBF Kernel</td><td style=text-align:center>99%</td><td style=text-align:center>12%</td></tr><tr><td style=text-align:center><strong>SVM Poly Kernel</strong></td><td style=text-align:center><strong>99%</strong></td><td style=text-align:center><strong>64%</strong></td></tr></tbody></table><p><strong>6 genre classes we are getting an accuracy of 85%</strong></p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>We have tried various machine learning algorithms for this project. Our aim is to get maximum accuracy. We have found from our research that we can a get maximum accuracy of <code>65%</code> by using <code>poly kernel SVM</code> for 10 genre classes. We have also tried to find the best combination of genre classes which will result in maximum accuracy. If we choose 6 genre classes we were able to get an accuracy of <code>85%</code>. We chose these labels for the Web Application [classical, hip-hop, jazz, metal, pop and rock]
For some songs we can say that it has feature of multiple genres. So we have also tried to get multiple label outputs based on the probability.</p></div><footer class=post-footer><nav class=paginav><a class=prev href=https://indrajith.me/posts/computerized-adaptive-test/><span class=title>« Prev Page</span><br><span>How to develop a Computerized Adaptive Test (CAT)</span></a>
<a class=next href=https://indrajith.me/posts/music-visualizer-in-c-using-opengl/><span class=title>Next Page »</span><br><span>Music Visualizer in C Using OpenGL</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://indrajith.me/>Indrajith Indraprastham</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script><script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('button');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script></body></html>