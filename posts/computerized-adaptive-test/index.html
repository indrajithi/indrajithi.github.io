<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>How to develop a Computerized Adaptive Test (CAT) | Indrajith Indraprastham</title><meta name=keywords content><meta name=description content="In this post, I’ll share the step by step process we used at AirCTO to create computerized adaptive tests.
At AirCTO we use adaptive tests to measure the ability of the candidate in different domains (Python, Front end development, Docker etc,.).
Back to basics: What is computerized adaptive test?  Computerized adaptive testing (CAT)) is a form of computer-based test that adapts to the examinee&rsquo;s ability level. For this reason, it has also been called tailored testing."><meta name=author content="Indrajith Indraprastham"><link rel=canonical href=https://indrajith.me/posts/computerized-adaptive-test/><link crossorigin=anonymous href=/assets/css/stylesheet.min.65aebb33e4f0ce3d1a39e4a35c11b91eb08b582489fca0f78f9227d90ac72a52.css integrity="sha256-Za67M+Twzj0aOeSjXBG5HrCLWCSJ/KD3j5In2QrHKlI=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://indrajith.me/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://indrajith.me/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://indrajith.me/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://indrajith.me/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://indrajith.me/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.82.1"><meta property="og:title" content="How to develop a Computerized Adaptive Test (CAT)"><meta property="og:description" content="In this post, I’ll share the step by step process we used at AirCTO to create computerized adaptive tests.
At AirCTO we use adaptive tests to measure the ability of the candidate in different domains (Python, Front end development, Docker etc,.).
Back to basics: What is computerized adaptive test?  Computerized adaptive testing (CAT)) is a form of computer-based test that adapts to the examinee&rsquo;s ability level. For this reason, it has also been called tailored testing."><meta property="og:type" content="article"><meta property="og:url" content="https://indrajith.me/posts/computerized-adaptive-test/"><meta property="og:image" content="https://indrajith.me/dp.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-03-25T16:05:28+05:30"><meta property="article:modified_time" content="2019-03-25T16:05:28+05:30"><meta property="og:site_name" content="Indrajith Indraprastham"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://indrajith.me/dp.jpg"><meta name=twitter:title content="How to develop a Computerized Adaptive Test (CAT)"><meta name=twitter:description content="In this post, I’ll share the step by step process we used at AirCTO to create computerized adaptive tests.
At AirCTO we use adaptive tests to measure the ability of the candidate in different domains (Python, Front end development, Docker etc,.).
Back to basics: What is computerized adaptive test?  Computerized adaptive testing (CAT)) is a form of computer-based test that adapts to the examinee&rsquo;s ability level. For this reason, it has also been called tailored testing."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://indrajith.me/posts/"},{"@type":"ListItem","position":2,"name":"How to develop a Computerized Adaptive Test (CAT)","item":"https://indrajith.me/posts/computerized-adaptive-test/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"How to develop a Computerized Adaptive Test (CAT)","name":"How to develop a Computerized Adaptive Test (CAT)","description":"In this post, I’ll share the step by step process we used at AirCTO to create computerized adaptive tests.\nAt AirCTO we use adaptive tests to measure the ability of the candidate in different domains (Python, Front end development, Docker etc,.).\nBack to basics: What is computerized adaptive test?  Computerized adaptive testing (CAT)) is a form of computer-based test that adapts to the examinee\u0026rsquo;s ability level. For this reason, it has also been called tailored testing.","keywords":[],"articleBody":"In this post, I’ll share the step by step process we used at AirCTO to create computerized adaptive tests.\nAt AirCTO we use adaptive tests to measure the ability of the candidate in different domains (Python, Front end development, Docker etc,.).\nBack to basics: What is computerized adaptive test?  Computerized adaptive testing (CAT)) is a form of computer-based test that adapts to the examinee’s ability level. For this reason, it has also been called tailored testing. In other words, it is a form of computer-administered test in which the next item or set of items selected to be administered depends on the correctness of the test taker’s responses to the most recent items administered.\n Why we use the adaptive test? Adaptive tests are designed to challenge candidates. High-achieving candidates who take a test that is designed around an average are not challenged by questions below their individual achievement abilities.\nLikewise, if lower-achieving candidates served by questions that are far above their current abilities they are left guessing the answers instead of applying what they already know.\nAdaptive testing addresses these issues by adjusting the questions to the individual proficiency of the candidate. High-achieving candidates are challenged by more difficult questions, while candidates who are slightly below the average are not overwhelmed but rather encouraged to continue moving forward by answering questions at or slightly above their current achievement level.\n  This motivates candidates to reach slightly beyond their comfort zone no matter where that zone might be-and prevents them from getting discouraged.\n  The adaptive test is based on a statistical model defined by the Item Response Theory.\n  We measure the ability of the candidate and the question difficulty on the same scale.\n   True Score/ True Ability: True score is the score an examinee would receive on a perfectly reliable test. Since all tests contain error, true scores are a theoretical concept; in an actual testing program, we will never know an individual’s true score.\n  We can however, compute an estimate of an examinee’s true score and we can estimate the amount of error in that estimate. True ability is denoted as θ; the true score for examinee j is denoted θ-j.\n Item Response Theory (IRT): Item Response Theory (IRT) is a statistical framework in which examinees can be described by a set of one or more ability scores that are predictive, through mathematical models, linking actual performance on test items, item statistics, and examinee abilities.\nIRT states that the probability of an examinee correctly answering the question is a function of the candidates true ability (θ) and the difficulty of the question (bi).\nSource\nUnder the 3 parameter IRT model, the probability of a correct response to a given item is a function of an examinee’s true ability and three item parameters:\nItem parameters: The parameters are calculated based on prior administrations of the items to a sample population. This is called pilot-test. It is possible to calibrate item parameters from the responses on a test.\nInitial item parameters are selected by modeling IRT parameters with responses from a sample population.\n1. ai : Item Discrimination Parameter This parameter shows how well an item (question) discriminates individuals who answer the item correctly and those who don’t.\nAn item with a high value tends to be answered correctly by all individuals whose θ is above the items' difficulty level and wrongly by all the others.\n2. bi : Item Difficulty Parameter b represents an item’s difficulty parameter. This parameter is measured on the same scale as θ. It shows at which point of the proficiency scale the item is more is informative, that is, where it discriminates the individuals who agree and those who disagree with the item.\nSince b and θ are measured in the same scale, b follows the same distributions as θ.\nFor a CAT, it is good for an item bank to have as many items as possible in all difficulty levels, so that the CAT may select the best item for each individual in all ability levels.\n3. ci : Guessing parameter c represents an item’s pseudo-guessing parameter. This parameter denotes what is the probability of individuals with low proficiency values to answer the item correctly. Since c is a probability, 0Let’s assume that you are given a question with four options and you do know the correct answer. If you select an answer randomly there is a 0.25 chance of success. This is the guessing parameter.\nSome times when you know the answer partially, one question might feel more probable than others. In this case the guessing parameter will be the highest probable one.\n4. di : Upper asymptote  An asymptote of a curve is a line such that the distance between the curve and the line approaches zero as one or both of the x or y coordinates tends to infinity.\n d represents an item’s upper asymptote. This parameter denotes what is the probability of individuals with high proficiency values to still answer the item incorrectly.\nSince d is a probability, 0In our implementation, we have used three-parameter model (3PL) with parameters a, b, c and d is a constant numpy.ones((n)).\n Each item has a different set of these three parameters. These parameters are usually calculated based on prior administrations of the item.\n  You can simulate these parameters using the following probability distributions:\n discrimination: N(1.2,0.25) difficulty: N(0,1) pseudo_guessing: N(0.25,0.02) upper asymptote: N(0.93,0.02)  \n Once we have enough samples these item parameters can be re-calibrated for better performance. θ is the examinee’s true ability, θ^ is the estimated ability.\n The 3PL IRT model states that probability of a correct response to an item i for an examinee is a function of the three item parameters and examinee j’s true ability θj.\nUnder IRT, the probability of an examinee with a given θ^ value (estimated ability), to answer item i correctly, given the item parameters, is given by:\nWith IRT, maximum information can be quantified as the standardized slope of ( θ) at θ^ . In other words\nThe CAT (Computerized Adaptive Test) algorithm: is usually an iterative process with the following steps:\n  Ability Estimation: All the items that have not yet been administered are evaluated to determine which will be the best one to administer as next-item, given the currently estimated ability level.\n  Item Selection: The “best” next item is administered and the examinee responds.\n  A new ability estimate is computed based on the responses to all of the administered items.(Log likelyhood, DifferentialEvolutionEstimator, HillClimbingEstimator)\n  Steps 1 through 3 are repeated until a stopping criterion is met.\n  Ability Initialisation: (only first time) We can initialize Randomly or on Fixed Point (-4, 4).\nAbility estimation: (except first time): A new ability estimate is computed based on the responses to all of the administered items. There are two main types of ways of estimating θ^: and these are the Bayesian methods and maximum-likelihood ones.\n Maximum-likelihood methods choose the θ^ value that maximizes the log likelihood of an examinee having a certain response vector, given the corresponding item parameters.\n  Bayesian methods used a priori information (usually assuming proficiency and parameter distributions) to make new estimations. The knowledge of new estimations is then used to make new assumptions about the parameter distributions, refining future estimations. [1]\n Item Selection: We used an implementation of the random sequence selector in which, at every step of the test, an item is randomly chosen from the n most informative items in the item bank, n being a predefined value.\nStopping rule: The stopping criterion could be time, the number of items administered, change in ability estimate, content coverage, a precision indicator such as the standard error.\n We use a combination of : time, ability estimate and precision.\n In other words:\n With IRT, maximum information can be quantified as the standardised slope of Pi( theta ) at theta_hat.\n  Cut Score Determination: While there are many methods for setting the cut score, there are a few that easily incorporate the information provided by IRT methods.\n  That is, many methods such as The θ values obtained via IRT provide a unique opportunity to get a more reliable estimate of respondent scores, and you are wise to look for a cut score method that can incorporate that info and typically use observed scores for determining the cut score, and inherently ignore the measurement error involved in that. in IRT: Pass/Fail\n The adaptive test will give the ability of the user in the interval -4 to +4 (low, high). We can either use this scale or convert it to a different scale: Transform your data using a desired mean and standard deviation.\nReference  A visual guide to item response theory Interactive, Computer Adaptive Testing Tutorial. Cut Score Determination Computerized Adaptive Testing Simulator  ","wordCount":"1483","inLanguage":"en","datePublished":"2019-03-25T16:05:28+05:30","dateModified":"2019-03-25T16:05:28+05:30","author":{"@type":"Person","name":"Indrajith Indraprastham"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://indrajith.me/posts/computerized-adaptive-test/"},"publisher":{"@type":"Organization","name":"Indrajith Indraprastham","logo":{"@type":"ImageObject","url":"https://indrajith.me/%3Clink%20/%20abs%20url%3E"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://indrajith.me/ accesskey=h title="< /> (Alt + H)">&lt; /></a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://indrajith.me/>Home</a>&nbsp;»&nbsp;<a href=https://indrajith.me/posts/>Posts</a></div><h1 class=post-title>How to develop a Computerized Adaptive Test (CAT)</h1><div class=post-meta>March 25, 2019&nbsp;·&nbsp;7 min&nbsp;·&nbsp;Indrajith Indraprastham</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><div class=details>Table of Contents</div></summary><div class=inner><ul><ul><ul><li><a href=#back-to-basics-what-is-computerized-adaptive-test aria-label="Back to basics: What is computerized adaptive test?">Back to basics: What is computerized adaptive test?</a></li></ul><li><a href=#why-we-use-the-adaptive-test aria-label="Why we use the adaptive test?">Why we use the adaptive test?</a></li><li><a href=#item-response-theory-irt aria-label="Item Response Theory (IRT):">Item Response Theory (IRT):</a></li></ul><li><a href=#item-parameters aria-label="Item parameters:">Item parameters:</a><ul><li><a href=#1-ai--item-discrimination-parameter aria-label="1. ai : Item Discrimination Parameter">1. <code>ai</code> : Item Discrimination Parameter</a></li><li><a href=#2-bi--item-difficulty-parameter aria-label="2. bi : Item Difficulty Parameter">2. <code>bi</code> : Item Difficulty Parameter</a></li><li><a href=#3-ci--guessing-parameter aria-label="3. ci : Guessing parameter">3. <code>ci</code> : Guessing parameter</a></li><li><a href=#4-di--upper-asymptote aria-label="4. di : Upper asymptote">4. <code>di</code> : Upper asymptote</a></li><li><a href=#item-selection aria-label="Item Selection:">Item Selection:</a></li><li><a href=#stopping-rule aria-label="Stopping rule:">Stopping rule:</a></li><li><a href=#reference aria-label=Reference>Reference</a></li></ul></li></ul></div></details></div><div class=post-content><p><img loading=lazy src=/cat-test.png alt="Cat test"></p><p>In this post, I’ll share the step by step process we used at <a href=https://www.linkedin.com/company/aircto/>AirCTO</a> to create computerized adaptive tests.</p><p>At AirCTO we use adaptive tests to measure the ability of the candidate in different domains <em>(Python, Front end development, Docker etc,.)</em>.</p><h3 id=back-to-basics-what-is-computerized-adaptive-test>Back to basics: What is computerized adaptive test?<a hidden class=anchor aria-hidden=true href=#back-to-basics-what-is-computerized-adaptive-test>#</a></h3><blockquote><p><a href=https://en.wikipedia.org/wiki/Computerized_adaptive_testing>Computerized adaptive testing (CAT)</a>) is a form of computer-based test that adapts to the examinee&rsquo;s ability level. For this reason, it has also been called tailored testing. In other words, it is a form of computer-administered test in which the next item or set of items selected to be administered depends on the correctness of the test taker&rsquo;s responses to the most recent items administered.</p></blockquote><p><img loading=lazy src=/cat.png alt="Adaptive test"></p><h2 id=why-we-use-the-adaptive-test>Why we use the adaptive test?<a hidden class=anchor aria-hidden=true href=#why-we-use-the-adaptive-test>#</a></h2><p>Adaptive tests are designed to challenge candidates. High-achieving candidates who take a test that is designed around an average are not challenged by questions below their individual achievement abilities.</p><p>Likewise, if lower-achieving candidates served by questions that are far above their current abilities they are left guessing the answers instead of applying what they already know.</p><p><img loading=lazy src=/aircto-cat.gif alt="Aircto Cat Test"></p><p><strong>Adaptive testing</strong> addresses these issues by adjusting the questions to the individual proficiency of the candidate. High-achieving candidates are challenged by more difficult questions, while candidates who are slightly below the average are not overwhelmed but rather encouraged to continue moving forward by answering questions at or slightly above their current achievement level.</p><ul><li><p>This motivates candidates to reach slightly beyond their comfort zone no matter where that zone might be-and prevents them from getting discouraged.</p></li><li><p>The adaptive test is based on a statistical model defined by the <a href=https://en.wikipedia.org/wiki/Item_response_theory>Item Response Theory</a>.</p></li><li><p>We measure the ability of the candidate and the question difficulty on the same scale.</p></li></ul><blockquote><p><strong>True Score/ True Ability:</strong>
True score is the score an examinee would receive on a perfectly reliable test.
Since all tests contain error, true scores are a theoretical concept; in an actual testing program, we will never know an individual’s true score.</p></blockquote><blockquote><p>We can however, compute an estimate of an examinee’s true score and we can estimate the amount of error in that estimate.
True ability is denoted as θ; the true score for examinee j is denoted θ-j.</p></blockquote><h2 id=item-response-theory-irt>Item Response Theory (IRT):<a hidden class=anchor aria-hidden=true href=#item-response-theory-irt>#</a></h2><p>Item Response Theory (IRT) is a statistical framework in which examinees can be described by a set of one or more ability scores that are predictive, through mathematical models, linking actual performance on test items, item statistics, and examinee abilities.</p><p>IRT states that the probability of an examinee correctly answering the question is a function of the candidates true ability (θ) and the difficulty of the question (bi).</p><p><img loading=lazy src=/irt.png alt="Item response theory">
<img loading=lazy src=/irt2.png alt="2pl Model"></p><p><a href=http://doingbayesiandataanalysis.blogspot.com/2015/12/bayesian-item-response-theory-in-jags.html>Source</a></p><p>Under the <strong>3 parameter IRT model</strong>, the probability of a correct response to a given item is a function of an examinee’s <em>true ability</em> and three <em>item parameters</em>:</p><h1 id=item-parameters>Item parameters:<a hidden class=anchor aria-hidden=true href=#item-parameters>#</a></h1><p>The parameters are calculated based on prior administrations of the items to a sample population. This is called pilot-test. It is possible to calibrate item parameters from the responses on a test.</p><p>Initial item parameters are selected by modeling IRT parameters with responses from a sample population.</p><h2 id=1-ai--item-discrimination-parameter>1. <code>ai</code> : Item Discrimination Parameter<a hidden class=anchor aria-hidden=true href=#1-ai--item-discrimination-parameter>#</a></h2><p>This parameter shows how well an item (question) discriminates individuals who answer the item correctly and those who don’t.</p><p>An item with a high value tends to be answered correctly by all individuals whose θ is above the items' difficulty level and wrongly by all the others.</p><h2 id=2-bi--item-difficulty-parameter>2. <code>bi</code> : Item Difficulty Parameter<a hidden class=anchor aria-hidden=true href=#2-bi--item-difficulty-parameter>#</a></h2><p><code>b</code> represents an item’s <code>difficulty parameter</code>. This parameter is measured on the same scale as θ. It shows at which point of the proficiency scale the item is more is informative, that is, where it discriminates the individuals who agree and those who disagree with the item.</p><p>Since b and θ are measured in the same scale, b follows the same distributions as θ.</p><p>For a CAT, it is good for an item bank to have as many items as possible in all difficulty levels, so that the CAT may select the best item for each individual in all ability levels.</p><h2 id=3-ci--guessing-parameter>3. <code>ci</code> : Guessing parameter<a hidden class=anchor aria-hidden=true href=#3-ci--guessing-parameter>#</a></h2><p><code>c</code> represents an item’s <code>pseudo-guessing parameter</code>. This parameter denotes what is the probability of individuals with low proficiency values to answer the item correctly. Since c is a probability, 0&lt; c ≤1, the lower the value of this parameter, the better the item is considered.</p><p>Let’s assume that you are given a question with four options and you do know the correct answer. If you select an answer randomly there is a 0.25 chance of success. This is the guessing parameter.</p><p>Some times when you know the answer partially, one question might feel more probable than others. In this case the guessing parameter will be the highest probable one.</p><h2 id=4-di--upper-asymptote>4. <code>di</code> : Upper asymptote<a hidden class=anchor aria-hidden=true href=#4-di--upper-asymptote>#</a></h2><blockquote><p>An <strong>asymptote</strong> of a <a href=https://en.wikipedia.org/wiki/Curve>curve</a> is a line such that the distance between the curve and the line approaches zero as one or both of the x or y coordinates <a href=https://en.wikipedia.org/wiki/Limit_of_a_function#Limits_at_infinity>tends to infinity</a>.</p></blockquote><p><img loading=lazy src=/asymptote.png alt=Asymptote>
<code>d</code> represents an item’s <code>upper asymptote</code>. This parameter denotes what is the probability of individuals with high proficiency values to still answer the item incorrectly.</p><p>Since d is a probability, 0&lt; d ≤1, the higher the value of this parameter, the better the item is considered.</p><p>In our implementation, we have used three-parameter model (3PL) with parameters <code>a, b, c and d</code> is a constant <em>numpy.ones((n))</em>.</p><p><img loading=lazy src=/principals-of-cat.png alt="Principal of cat"></p><blockquote><p>Each item has a different set of these three parameters. These parameters are usually calculated based on prior administrations of the item.</p></blockquote><blockquote><p><strong>You can simulate these parameters using the following probability distributions:</strong></p></blockquote><pre><code>discrimination: N(1.2,0.25) difficulty: N(0,1)
pseudo_guessing: N(0.25,0.02) upper asymptote: N(0.93,0.02)
</code></pre><p><br><br><br><img loading=lazy src=/item-parameters.jpeg alt="Item parameters"></p><blockquote><p>Once we have enough samples these <strong>item parameters</strong> can be re-calibrated for better performance.
<strong>θ</strong> is the examinee’s true ability, <strong>θ^</strong> is the <strong>estimated</strong> <strong>ability</strong>.</p></blockquote><p>The <strong>3PL</strong> <strong>IRT</strong> model states that probability of a correct response to an item <strong>i</strong> for an examinee is a function of the <strong>three item parameters</strong> and examinee <strong>j</strong>’s true <strong>ability θj</strong>.</p><p>Under IRT, the <strong>probability</strong> of an examinee with a given θ^ value (<em>estimated</em> <em>ability</em>), to <strong>answer item i correctly</strong>, given the item parameters, is given by:</p><p><img loading=lazy src=/p-correct-answer-irt.png alt="Correct Answer"></p><p>With IRT, maximum information can be quantified as the standardized slope of ( θ) at θ^ . In other words</p><p><img loading=lazy src=/images/information-irt.png alt="Information IRT"></p><p><strong>The CAT (Computerized Adaptive Test) algorithm: is usually an iterative process with the following steps:</strong></p><ul><li><p><strong>Ability Estimation</strong>: All the items that have not yet been administered are evaluated to determine which will be the best one to administer as next-item, given the currently estimated ability level.</p></li><li><p><strong>Item Selection:</strong> The “best” next item is administered and the examinee responds.</p></li><li><p>A new ability estimate is computed based on the responses to all of the administered items.<code>(Log likelyhood, DifferentialEvolutionEstimator, HillClimbingEstimator)</code></p></li><li><p><strong>Steps 1</strong> through <strong>3</strong> are repeated until a <strong>stopping criterion</strong> is met.</p></li></ul><p><img loading=lazy src=/images/irt-steps.png alt="IRT steps"></p><p><strong>Ability Initialisation:</strong> <em>(only first time)</em>
We can initialize Randomly or on Fixed Point <em>(-4, 4)</em>.</p><p><strong>Ability estimation:</strong> <em>(except first time)</em>:
A new ability estimate is computed based on the responses to all of the administered items. There are two main types of ways of estimating θ^: and these are the <em>Bayesian methods</em> and <em>maximum-likelihood</em> ones.</p><blockquote><p><strong>Maximum-likelihood</strong> methods choose the θ^ value that maximizes the log likelihood of an examinee having a certain response vector, given the corresponding item parameters.</p></blockquote><blockquote><p><strong>Bayesian methods</strong> used a priori information (usually assuming proficiency and parameter distributions) to make new estimations. The knowledge of new estimations is then used to make new assumptions about the parameter distributions, refining future estimations. [<a href=https://pythonhosted.org/catsim/estimation.html>1</a>]</p></blockquote><h2 id=item-selection>Item Selection:<a hidden class=anchor aria-hidden=true href=#item-selection>#</a></h2><p>We used an implementation of the <strong>random sequence selector</strong> in which, at every step of the test, an item is randomly chosen from the <em>n</em> most <strong>informative items</strong> in the item bank, <em>n</em> being a predefined value.</p><h2 id=stopping-rule>Stopping rule:<a hidden class=anchor aria-hidden=true href=#stopping-rule>#</a></h2><p>The stopping criterion could be time, the number of items administered, change in ability estimate, content coverage, a precision indicator such as the standard error.</p><blockquote><p>We use a combination of : time, ability estimate and precision.</p></blockquote><p><em>In other words:</em></p><blockquote><p>With IRT, maximum information can be quantified as the standardised slope of <strong>Pi( theta )</strong> at <strong>theta_hat</strong>.</p></blockquote><p><img loading=lazy src=/images/pass-fail.jpg alt="Pass fail"></p><blockquote><p><strong><a href=https://stats.stackexchange.com/a/134433/144825>Cut Score Determination</a></strong>: <em>While there are many methods for setting the cut score, there are a few that easily incorporate the information provided by IRT methods.</em></p></blockquote><blockquote><p><em>That is, many methods such as The θ values obtained via IRT provide a unique opportunity to get a more reliable estimate of respondent scores, and you are wise to look for a cut score method that can incorporate that info and typically use observed scores for determining the cut score, and inherently ignore the measurement error involved in that. in <strong>IRT: Pass/Fail</strong></em></p></blockquote><p>The adaptive test will give the ability of the user in the interval -4 to +4 (low, high). We can either use this scale or convert it to a different scale: Transform <a href=https://stats.stackexchange.com/a/46431/144825>your data using a desired mean and standard deviation.</a></p><h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><ol><li><a href=https://www.metheval.uni-jena.de/irt/VisualIRT.pdf>A visual guide to item response theory</a></li><li><a href=http://echo.edres.org:8080/scripts/cat/catdemo.htm#_1_9>Interactive, Computer Adaptive Testing Tutorial.</a></li><li><a href=https://stats.stackexchange.com/a/134433/144825>Cut Score Determination</a></li><li><a href=https://github.com/douglasrizzo/catsim>Computerized Adaptive Testing Simulator</a></li></ol></div><footer class=post-footer><nav class=paginav><a class=prev href=https://indrajith.me/posts/atomic-habits-book-summary/><span class=title>« Prev Page</span><br><span>Atomic Habits [Notes]</span></a>
<a class=next href=https://indrajith.me/posts/machine-learning-pproach-to-classify-music-based-on-genre/><span class=title>Next Page »</span><br><span>Machine Learning Approach to Classify Music Based on Genre</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2021 <a href=https://indrajith.me/>Indrajith Indraprastham</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>